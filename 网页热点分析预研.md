## 网页热点分析预研 ##

因为老徐那边的爬虫尚未完工，具体输出到kafka中的格式和内容也尚未确定，所以从kafka中取出title插入到ES这一步目前并无实质进展。目前做的只是个模拟。

1. 总体结构

  模拟计划中的整体的数据流大致是这个样子：
    
   > 网页 === （爬虫） ===> 文本文件 === （logstash） ===> kafka === （logstash） ===> ES

  目前进行到 从文本文件通过 logstash 输出到 kafka 这一步

2. 环境准备

  需要的环境：
  
   * kafka
   
   * ES
   
   * logstash
   
   * 爬虫
   
  开始尝试在可连外网的虚拟机中单独安装最新版的 kafka 和 ES，但是运行后发现单个虚拟机的性能不太能承受三个软件同时开启。并且全新单独安装后需要调整的参数也较多，还缺少可视化的网页管理端，故而最后决定还是使用内网测试环境中的现有的布置。
  
  在正式环境中，kafka 和 ES 一般会用 CDH 套件来安装。目前CDH套件中最新版本的kafka是0.9，而最新版的 logstash 支持的 kafka 客户端是 0.10，因而需要如同之前的日志输出一样，对 logstash 的 kafka 插件进行降级。之前仅仅将 input-kafka 降级到了4.1.1，这次需要将 output-kafka 也降级到4.1.1.
  
  降级过程如下：
  
  >  1. 找一个可连外网的机器，全新安装 logstash
    
  >  2. 执行：/usr/share/logstash/bin/logstash-plugin install --version 4.1.1 logstash-input-kafka
    
  >  3. 执行：/usr/share/logstash/bin/logstash-plugin install --version 4.1.1 logstash-outut-kafka
    
  >  4. 将/usr/share/logstash 文件夹整个打包，复制到内网机器。
    
  >  5. 删除内网机器上原有的 /usr/share/logstash文件夹。然后将复制过来的包解压过去。


3. 爬虫

  爬虫部分会有老徐那边来做，故而这次只是做了个demo用于模拟输出，仅能爬取部分指定页面的内容，适用性较窄。爬虫使用 python 的 BeautifulSoup 库进行编写。其中需要注意的点一个是 UserAgent 的模拟，一个是字符编码的设置。爬取的内容输出到一个文件。只爬title，输出格式为一行一条记录。

4. 在 kafka 中建立 topic

  > kafka-topics.sh --create --zookeeper 127.0.0.1:2181 --replication-factor 1 --partition 1 --topic titles

5. 从文本文件输出到 kafka

  配置logstash。输入插件选择使用 file， 输出插件为 kafka。配置文件目前如下：

  ```
    input {
        file {
            path => "/home/test/titlelist"
            start_position => "beginning"
        }
    }
    output {
        stdout {  codec => "rubydebug" } #观察是否有读取到内容用
        kafka {
            bootstrap_servers => "hzga173:9092,hzga174:9092"
            topic_id => "titles"
        }
    }
    
  ```

 然后启动 logstash。观察是否有输出。
 
   另起一个 kafka 的 consumer， 观察topic中是否有内容进入：
  
   > kafka-console-consumer.sh --bootstrap-server hzga173:9092,hzga174:9092 --topic titles --from-beginning 

  当前进度到此为止。

6. 从 kafka 到 ES

  前面的步骤老徐那边最后都会完成。从这里开始才是实质部分，但是目前还没着手开始做。初步计划是先逐个尝试下 logstash 中各个 filter 插件的实际效果，以应对老徐那边或许可能有的各种情况。